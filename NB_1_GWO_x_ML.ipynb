{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cWMbDPyFtA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c5e279-8537-4498-f5d7-d817aa8e71a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "5N5s0esEwlet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "from sklearn.impute import SimpleImputer\n",
        "from glob import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from hyperopt import fmin, tpe, hp, Trials\n",
        "from hyperopt.pyll.base import scope\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, LSTM, GRU, Dense\n",
        "from keras.optimizers import Adam\n",
        "from prophet import Prophet\n",
        "import gc\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "f7cKgm7jtuar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GreyWolf Optimization for Hyperparameter Tuning\n",
        "Source: https://github.com/Valdecy/pyMetaheuristic/blob/main/pyMetaheuristic/algorithm/gwo.py"
      ],
      "metadata": {
        "id": "a5iA0i4kxSo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Initialize Variables\n",
        "def initial_variables(size, min_values, max_values, target_function, start_init = None):\n",
        "    dim = len(min_values)\n",
        "    if (start_init is not None):\n",
        "        start_init = np.atleast_2d(start_init)\n",
        "        n_rows     = size - start_init.shape[0]\n",
        "        if (n_rows > 0):\n",
        "            rows       = np.random.uniform(min_values, max_values, (n_rows, dim))\n",
        "            start_init = np.vstack((start_init[:, :dim], rows))\n",
        "        else:\n",
        "            start_init = start_init[:size, :dim]\n",
        "        fitness_values = target_function(start_init) if hasattr(target_function, 'vectorized') else np.apply_along_axis(target_function, 1, start_init)\n",
        "        population     = np.hstack((start_init, fitness_values[:, np.newaxis] if not hasattr(target_function, 'vectorized') else fitness_values))\n",
        "    else:\n",
        "        population     = np.random.uniform(min_values, max_values, (size, dim))\n",
        "        fitness_values = target_function(population) if hasattr(target_function, 'vectorized') else np.apply_along_axis(target_function, 1, population)\n",
        "        population     = np.hstack((population, fitness_values[:, np.newaxis] if not hasattr(target_function, 'vectorized') else fitness_values))\n",
        "    return population\n",
        "\n",
        "############################################################################\n",
        "\n",
        "# Function: Initialize Alpha\n",
        "def alpha_position(min_values, max_values, target_function):\n",
        "    alpha       = np.zeros((1, len(min_values) + 1))\n",
        "    alpha[0,-1] = target_function(np.clip(alpha[0,0:alpha.shape[1]-1], min_values, max_values))\n",
        "    return alpha[0,:]\n",
        "\n",
        "\n",
        "# Function: Initialize Beta\n",
        "def beta_position(min_values, max_values, target_function):\n",
        "    beta       = np.zeros((1, len(min_values) + 1))\n",
        "    beta[0,-1] = target_function(np.clip(beta[0,0:beta.shape[1]-1], min_values, max_values))\n",
        "    return beta[0,:]\n",
        "\n",
        "\n",
        "# Function: Initialize Delta\n",
        "def delta_position(min_values, max_values, target_function):\n",
        "    delta       =  np.zeros((1, len(min_values) + 1))\n",
        "    delta[0,-1] = target_function(np.clip(delta[0,0:delta.shape[1]-1], min_values, max_values))\n",
        "    return delta[0,:]\n",
        "\n",
        "\n",
        "# Function: Updtade Pack by Fitness\n",
        "def update_pack(position, alpha, beta, delta):\n",
        "    idx   = np.argsort(position[:, -1])\n",
        "    alpha = position[idx[0], :]\n",
        "    beta  = position[idx[1], :] if position.shape[0] > 1 else alpha\n",
        "    delta = position[idx[2], :] if position.shape[0] > 2 else beta\n",
        "    return alpha, beta, delta\n",
        "\n",
        "\n",
        "# Function: Update Position\n",
        "def update_position(position, alpha, beta, delta, a_linear_component, min_values, max_values, target_function):\n",
        "    dim                     = len(min_values)\n",
        "    alpha_position          = np.copy(position)\n",
        "    beta_position           = np.copy(position)\n",
        "    delta_position          = np.copy(position)\n",
        "    updated_position        = np.copy(position)\n",
        "    r1                      = np.random.rand(position.shape[0], dim)\n",
        "    r2                      = np.random.rand(position.shape[0], dim)\n",
        "    a                       = 2 * a_linear_component * r1 - a_linear_component\n",
        "    c                       = 2 * r2\n",
        "    distance_alpha          = np.abs(c * alpha[:dim] - position[:, :dim])\n",
        "    distance_beta           = np.abs(c * beta [:dim] - position[:, :dim])\n",
        "    distance_delta          = np.abs(c * delta[:dim] - position[:, :dim])\n",
        "    x1                      = alpha[:dim] - a * distance_alpha\n",
        "    x2                      = beta [:dim] - a * distance_beta\n",
        "    x3                      = delta[:dim] - a * distance_delta\n",
        "    alpha_position[:,:-1]   = np.clip(x1, min_values, max_values)\n",
        "    beta_position [:,:-1]   = np.clip(x2, min_values, max_values)\n",
        "    delta_position[:,:-1]   = np.clip(x3, min_values, max_values)\n",
        "    alpha_position[:, -1]   = np.apply_along_axis(target_function, 1, alpha_position[:, :-1])\n",
        "    beta_position [:, -1]   = np.apply_along_axis(target_function, 1, beta_position [:, :-1])\n",
        "    delta_position[:, -1]   = np.apply_along_axis(target_function, 1, delta_position[:, :-1])\n",
        "    updated_position[:,:-1] = np.clip((alpha_position[:, :-1] + beta_position[:, :-1] + delta_position[:, :-1]) / 3, min_values, max_values)\n",
        "    updated_position[:, -1] = np.apply_along_axis(target_function, 1, updated_position[:, :-1])\n",
        "    updated_position        = np.vstack([position, updated_position, alpha_position, beta_position, delta_position])\n",
        "    updated_position        = updated_position[updated_position[:, -1].argsort()]\n",
        "    updated_position        = updated_position[:position.shape[0], :]\n",
        "    return updated_position\n",
        "\n",
        "\n",
        "def grey_wolf_optimizer(pack_size, min_values, max_values, iterations, target_function, verbose=True):\n",
        "    alpha = alpha_position(min_values, max_values, target_function)\n",
        "    beta = beta_position(min_values, max_values, target_function)\n",
        "    delta = delta_position(min_values, max_values, target_function)\n",
        "    position = initial_variables(pack_size, min_values, max_values, target_function)\n",
        "\n",
        "    for count in range(iterations):\n",
        "        if verbose:\n",
        "            print(f\"Iteration {count}/{iterations}: Best Fitness = {alpha[-1]}\")\n",
        "\n",
        "        a_linear_component = 2 - count * (2 / iterations)\n",
        "        alpha, beta, delta = update_pack(position, alpha, beta, delta)\n",
        "        position = update_position(position, alpha, beta, delta, a_linear_component, min_values, max_values, target_function)\n",
        "        alpha = position[position[:, -1].argsort()][0]\n",
        "\n",
        "    return map_params(alpha[:-1]), alpha[-1]"
      ],
      "metadata": {
        "id": "QpDeat2CuSPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Files"
      ],
      "metadata": {
        "id": "AzQpbehTwjBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject_files = glob(\"/content/drive/MyDrive/Upwork clients/ACCOUNT-CREATOR/DiaTrend Data/DiaTrend Data/Sensor Data/*.xlsx\")\n",
        "print(f\"Number of subject files found: {len(subject_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgN6Uwk4tVkg",
        "outputId": "0048d727-f263-44ce-81e6-46677bade07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of subject files found: 54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Configuration:\n",
        "##### **Note**: Set `Subjects` and `CGM_Inputs` in Conf class below as per your computation power"
      ],
      "metadata": {
        "id": "NsqiK5VsG_mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conf :\n",
        "    # dataloading values\n",
        "    Subjects = 20 # define how many subjects you want to include in processing\n",
        "    CGM_Inputs = 20000 # define how many CGM inputs (rows) to consider for training\n",
        "\n",
        "    # when you set iterator as 5 it would take input as a 6 (always plus one than input)\n",
        "    iterator = 3 # it would be recommended to set less than 10\n",
        "    iterator_deeplearning = 2 # deep learnig take time so set it to less than 5\n",
        "\n",
        "    # set agents value (number of wolves)\n",
        "    number_wolves = 10\n"
      ],
      "metadata": {
        "id": "fHkm5vzTQ5jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "MYLq9PPPxBMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lag_features(df, column, lags):\n",
        "    for lag in lags:\n",
        "        df[f'{column}_lag_{lag}'] = df[column].shift(lag)\n",
        "    return df\n",
        "\n",
        "# Placeholder for all data\n",
        "all_data = []\n",
        "\n",
        "# Iterate over each subject file\n",
        "for subject_file in tqdm(sorted(subject_files)[:min(Conf.Subjects, len(subject_files))]):\n",
        "    try:\n",
        "        print(f\"Processing {subject_file}...\")\n",
        "\n",
        "        # Load CGM and Bolus data for each subject\n",
        "        cgm_data = pd.read_excel(subject_file, sheet_name='CGM', parse_dates=['date'])\n",
        "        bolus_data = pd.read_excel(subject_file, sheet_name='Bolus', parse_dates=['date'])\n",
        "\n",
        "        # Check if data was loaded correctly\n",
        "        if cgm_data.empty or bolus_data.empty:\n",
        "            print(f\"No data found in {subject_file}\")\n",
        "            continue\n",
        "\n",
        "        cgm_data['date'] = pd.to_datetime(cgm_data['date'], format='ISO8601')\n",
        "        bolus_data['date'] = pd.to_datetime(bolus_data['date'], format='ISO8601')\n",
        "\n",
        "        # Drop columns with high NaN values\n",
        "        bolus_data.drop(columns=['recommended.carb', 'carbInput'], inplace=True)\n",
        "\n",
        "        # Preprocessing Bolus data\n",
        "        columns_to_impute_with_mean = ['normal', 'bgInput', 'recommended.net', 'recommended.correction', 'insulinOnBoard']\n",
        "        columns_to_impute_with_mode = ['insulinCarbRatio', 'insulinSensitivityFactor', 'targetBloodGlucose']\n",
        "\n",
        "        # Imputation\n",
        "        bolus_data[columns_to_impute_with_mean] = bolus_data[columns_to_impute_with_mean].fillna(bolus_data[columns_to_impute_with_mean].mean())\n",
        "        bolus_data[columns_to_impute_with_mode] = bolus_data[columns_to_impute_with_mode].fillna(bolus_data[columns_to_impute_with_mode].mode().iloc[0])\n",
        "\n",
        "        # Merge CGM and Bolus data on 'date'\n",
        "        merged_data = pd.merge_asof(cgm_data.sort_values('date'), bolus_data.sort_values('date'), on='date', direction='nearest')\n",
        "\n",
        "        # Create lagged features for forecasting\n",
        "        lagged_data = create_lag_features(merged_data, 'mg/dl', lags=[1, 2, 3, 4, 5])\n",
        "        lagged_data.dropna(inplace=True)\n",
        "        subject_id = os.path.basename(subject_file).replace(\"Subject\", \"\").replace(\".xlsx\", \"\")\n",
        "        lagged_data['subjectID'] = subject_id\n",
        "\n",
        "        if lagged_data.empty:\n",
        "            print(f\"No lagged data generated for {subject_file}\")\n",
        "            continue\n",
        "\n",
        "        # Append to the all_data list\n",
        "        all_data.append(lagged_data.head(min(Conf.CGM_Inputs,len(lagged_data))))\n",
        "\n",
        "    except Exception as ex:\n",
        "        print(f\"Error Occurred at {os.path.basename(subject_file)}: {str(ex)}\")\n",
        "\n",
        "# Check if all_data is empty before concatenation\n",
        "if not all_data:\n",
        "    print(\"No data was successfully processed. Exiting.\")\n",
        "else:\n",
        "    # Concatenate all subjects' data into a single DataFrame\n",
        "    final_data = pd.concat(all_data, axis=0).reset_index(drop=True)\n",
        "\n",
        "    # One-hot encoding for categorical columns\n",
        "    categorical_columns = ['subjectID']\n",
        "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "    encoded_categorical_data = pd.DataFrame(encoder.fit_transform(final_data[categorical_columns]),\n",
        "                                            columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "    # Drop original categorical columns and concatenate one-hot encoded columns\n",
        "    final_data = final_data.drop(columns=categorical_columns)\n",
        "    final_data = pd.concat([final_data, encoded_categorical_data], axis=1)\n",
        "\n",
        "    # Define features and target\n",
        "    X_prophet = final_data['date']\n",
        "    X = final_data.drop(columns=['date', 'mg/dl'])\n",
        "    y = final_data['mg/dl']\n",
        "\n",
        "    print(\"Dataset shape:\", X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m1wXsZnQ5FK",
        "outputId": "c745c7a8-999c-4c56-9f0e-19888a786b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/Upwork clients/ACCOUNT-CREATOR/DiaTrend Data/DiaTrend Data/Sensor Data/Subject1.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 1/2 [01:25<01:25, 85.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/Upwork clients/ACCOUNT-CREATOR/DiaTrend Data/DiaTrend Data/Sensor Data/Subject10.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [01:48<00:00, 54.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (1000, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "FsR2GLsavZ5a",
        "outputId": "f4fad8f7-a33e-497b-bd92-15b7a9cbbfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     normal  insulinCarbRatio     bgInput  recommended.net  \\\n",
              "995    11.0               5.5  247.298013              0.0   \n",
              "996    11.0               5.5  247.298013              0.0   \n",
              "997    11.0               5.5  247.298013              0.0   \n",
              "998    11.0               5.5  247.298013              0.0   \n",
              "999    11.0               5.5  247.298013              0.0   \n",
              "\n",
              "     recommended.correction  insulinSensitivityFactor  targetBloodGlucose  \\\n",
              "995                2.525214                      60.0               120.0   \n",
              "996                2.525214                      60.0               120.0   \n",
              "997                2.525214                      60.0               120.0   \n",
              "998                2.525214                      60.0               120.0   \n",
              "999                2.525214                      60.0               120.0   \n",
              "\n",
              "     insulinOnBoard  mg/dl_lag_1  mg/dl_lag_2  mg/dl_lag_3  mg/dl_lag_4  \\\n",
              "995             0.0        260.0        273.0        282.0        283.0   \n",
              "996             0.0        240.0        260.0        273.0        282.0   \n",
              "997             0.0        219.0        240.0        260.0        273.0   \n",
              "998             0.0        212.0        219.0        240.0        260.0   \n",
              "999             0.0        200.0        212.0        219.0        240.0   \n",
              "\n",
              "     mg/dl_lag_5  subjectID_10  \n",
              "995        290.0           1.0  \n",
              "996        283.0           1.0  \n",
              "997        282.0           1.0  \n",
              "998        273.0           1.0  \n",
              "999        260.0           1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6c09145-0ef5-438b-9546-d893c0f3be70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>normal</th>\n",
              "      <th>insulinCarbRatio</th>\n",
              "      <th>bgInput</th>\n",
              "      <th>recommended.net</th>\n",
              "      <th>recommended.correction</th>\n",
              "      <th>insulinSensitivityFactor</th>\n",
              "      <th>targetBloodGlucose</th>\n",
              "      <th>insulinOnBoard</th>\n",
              "      <th>mg/dl_lag_1</th>\n",
              "      <th>mg/dl_lag_2</th>\n",
              "      <th>mg/dl_lag_3</th>\n",
              "      <th>mg/dl_lag_4</th>\n",
              "      <th>mg/dl_lag_5</th>\n",
              "      <th>subjectID_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>11.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>247.298013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.525214</td>\n",
              "      <td>60.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>11.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>247.298013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.525214</td>\n",
              "      <td>60.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>11.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>247.298013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.525214</td>\n",
              "      <td>60.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>11.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>247.298013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.525214</td>\n",
              "      <td>60.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>11.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>247.298013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.525214</td>\n",
              "      <td>60.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6c09145-0ef5-438b-9546-d893c0f3be70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6c09145-0ef5-438b-9546-d893c0f3be70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6c09145-0ef5-438b-9546-d893c0f3be70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a165955e-6035-4905-9c39-c76792c82386\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a165955e-6035-4905-9c39-c76792c82386')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a165955e-6035-4905-9c39-c76792c82386 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"normal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 11.0,\n        \"max\": 11.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulinCarbRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.5,\n        \"max\": 5.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bgInput\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 247.2980132450331,\n        \"max\": 247.2980132450331,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          247.2980132450331\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recommended.net\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recommended.correction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 2.5252142857142856,\n        \"max\": 2.5252142857142856,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.5252142857142856\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulinSensitivityFactor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 60.0,\n        \"max\": 60.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          60.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"targetBloodGlucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 120.0,\n        \"max\": 120.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          120.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulinOnBoard\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mg/dl_lag_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.836946113124476,\n        \"min\": 200.0,\n        \"max\": 260.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          240.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mg/dl_lag_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.032671779899967,\n        \"min\": 212.0,\n        \"max\": 273.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          260.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mg/dl_lag_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.48921340488953,\n        \"min\": 219.0,\n        \"max\": 282.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          273.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mg/dl_lag_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.98054504179448,\n        \"min\": 240.0,\n        \"max\": 283.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          282.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mg/dl_lag_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.545561917897283,\n        \"min\": 260.0,\n        \"max\": 290.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          283.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subjectID_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yot6Pct2vnnL",
        "outputId": "4519dd5c-1d8e-4101-df16-3105f07bef54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 14 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   normal                    1000 non-null   float64\n",
            " 1   insulinCarbRatio          1000 non-null   float64\n",
            " 2   bgInput                   1000 non-null   float64\n",
            " 3   recommended.net           1000 non-null   float64\n",
            " 4   recommended.correction    1000 non-null   float64\n",
            " 5   insulinSensitivityFactor  1000 non-null   float64\n",
            " 6   targetBloodGlucose        1000 non-null   float64\n",
            " 7   insulinOnBoard            1000 non-null   float64\n",
            " 8   mg/dl_lag_1               1000 non-null   float64\n",
            " 9   mg/dl_lag_2               1000 non-null   float64\n",
            " 10  mg/dl_lag_3               1000 non-null   float64\n",
            " 11  mg/dl_lag_4               1000 non-null   float64\n",
            " 12  mg/dl_lag_5               1000 non-null   float64\n",
            " 13  subjectID_10              1000 non-null   float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 109.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9pvknEvzMJ6",
        "outputId": "cd7de916-b86c-409d-ae4d-9010e3926ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 14) (800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an initial DataFrame to store the results\n",
        "ResultDF = pd.DataFrame(columns=[\"modelName\", \"subjects\", \"datasetLength\", \"MAE\", \"RMSE\", \"MAPE\"])"
      ],
      "metadata": {
        "id": "gSft-GsZzC4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning X Model Training"
      ],
      "metadata": {
        "id": "n3rmBbz_ykPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost"
      ],
      "metadata": {
        "id": "pKWi7btlLxx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameter space for XGBoost\n",
        "space_xgboost = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "def map_params(position):\n",
        "    indices = [\n",
        "        min(int(position[0] * len(space_xgboost['n_estimators'])), len(space_xgboost['n_estimators']) - 1),\n",
        "        min(int(position[1] * len(space_xgboost['max_depth'])), len(space_xgboost['max_depth']) - 1),\n",
        "        min(int(position[2] * len(space_xgboost['learning_rate'])), len(space_xgboost['learning_rate']) - 1),\n",
        "        min(int(position[3] * len(space_xgboost['subsample'])), len(space_xgboost['subsample']) - 1),\n",
        "        min(int(position[4] * len(space_xgboost['colsample_bytree'])), len(space_xgboost['colsample_bytree']) - 1)\n",
        "    ]\n",
        "    params = {\n",
        "        'n_estimators': space_xgboost['n_estimators'][indices[0]],\n",
        "        'max_depth': space_xgboost['max_depth'][indices[1]],\n",
        "        'learning_rate': space_xgboost['learning_rate'][indices[2]],\n",
        "        'subsample': space_xgboost['subsample'][indices[3]],\n",
        "        'colsample_bytree': space_xgboost['colsample_bytree'][indices[4]]\n",
        "    }\n",
        "    return params\n",
        "\n",
        "def xgb_target_function(position):\n",
        "    params = map_params(position)\n",
        "    model = xgb.XGBRegressor(\n",
        "        verbosity=0,\n",
        "        objective='reg:squarederror',\n",
        "        n_estimators=params['n_estimators'],\n",
        "        max_depth=params['max_depth'],\n",
        "        learning_rate=params['learning_rate'],\n",
        "        subsample=params['subsample'],\n",
        "        colsample_bytree=params['colsample_bytree'],\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    return mse\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Configuration for the GWO\n",
        "dim = 5 # do not change this dimension\n",
        "n_agents = Conf.number_wolves\n",
        "n_iter = Conf.iterator\n",
        "min_values = [0] * dim  # np.zeros(dim)\n",
        "max_values = [1] * dim  # np.ones(dim)\n",
        "\n",
        "# Run Grey Wolf Optimizer\n",
        "best_params, best_score = grey_wolf_optimizer(\n",
        "    pack_size=n_agents,\n",
        "    min_values=min_values,\n",
        "    max_values=max_values,\n",
        "    iterations=n_iter,\n",
        "    target_function=xgb_target_function,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score (MSE):\", best_score)\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Train XGBoost with best_params\n",
        "model = xgb.XGBRegressor(\n",
        "    verbosity=0,\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    subsample=best_params['subsample'],\n",
        "    colsample_bytree=best_params['colsample_bytree'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model with training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, preds)\n",
        "mape = mean_absolute_percentage_error(y_test, preds)\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAPE:\", mape)\n",
        "\n",
        "# Append result in dataframe\n",
        "row_result = [\"XGBoost\", Conf.Subjects, Conf.Subjects * Conf.CGM_Inputs, mae, rmse, mape]\n",
        "\n",
        "ResultDF.loc[len(ResultDF)] = row_result\n",
        "\n",
        "del best_params, best_score\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "xSsdZAePui7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37410346-36a5-43da-d3bc-cfd0887e82cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0/3: Best Fitness = 1087.5432631012327\n",
            "Iteration 1/3: Best Fitness = 59.63463684372655\n",
            "Iteration 2/3: Best Fitness = 56.408846781468675\n",
            "Best Parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
            "Best Score (MSE): 56.408846781468675\n",
            "MAE: 5.353049716949463\n",
            "RMSE: 7.510582319731851\n",
            "MAPE: 0.03776313134872288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3278"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "Tq8EQCa6zkgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter space for Random Forest\n",
        "space_rf = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees\n",
        "    'max_depth': [None, 10, 20],  # Maximum depth of each tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4]  # Minimum samples required at a leaf node\n",
        "}\n",
        "\n",
        "def map_params(position):\n",
        "    indices = [\n",
        "        min(int(position[0] * len(space_rf['n_estimators'])), len(space_rf['n_estimators']) - 1),\n",
        "        min(int(position[1] * len(space_rf['max_depth'])), len(space_rf['max_depth']) - 1),\n",
        "        min(int(position[2] * len(space_rf['min_samples_split'])), len(space_rf['min_samples_split']) - 1),\n",
        "        min(int(position[3] * len(space_rf['min_samples_leaf'])), len(space_rf['min_samples_leaf']) - 1)\n",
        "    ]\n",
        "    params = {\n",
        "        'n_estimators': space_rf['n_estimators'][indices[0]],\n",
        "        'max_depth': space_rf['max_depth'][indices[1]],\n",
        "        'min_samples_split': space_rf['min_samples_split'][indices[2]],\n",
        "        'min_samples_leaf': space_rf['min_samples_leaf'][indices[3]]\n",
        "    }\n",
        "    return params\n",
        "def rf_target_function(position):\n",
        "    params = map_params(position)\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=params['n_estimators'],\n",
        "        max_depth=params['max_depth'],\n",
        "        min_samples_split=params['min_samples_split'],\n",
        "        min_samples_leaf=params['min_samples_leaf'],\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    return mse\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Configuration for the GWO\n",
        "dim = 4  # Number of hyperparameters for Random Forest\n",
        "n_agents = Conf.number_wolves\n",
        "n_iter = Conf.iterator\n",
        "min_values = [0] * dim  # Lower bounds\n",
        "max_values = [1] * dim  # Upper bounds\n",
        "\n",
        "# Run Grey Wolf Optimizer for Random Forest\n",
        "best_params, best_score = grey_wolf_optimizer(\n",
        "    pack_size=n_agents,\n",
        "    min_values=min_values,\n",
        "    max_values=max_values,\n",
        "    iterations=n_iter,\n",
        "    target_function=rf_target_function,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score (MSE):\", best_score)\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Train Random Forest with best_params\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    min_samples_split=best_params['min_samples_split'],\n",
        "    min_samples_leaf=best_params['min_samples_leaf'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model with training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, preds)\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "rmse = np.sqrt(mse)\n",
        "mape = mean_absolute_percentage_error(y_test, preds)\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAPE:\", mape)\n",
        "\n",
        "# Append result in dataframe\n",
        "row_result = [\"Random Forest\", Conf.Subjects, Conf.Subjects * Conf.CGM_Inputs, mae, rmse, mape]\n",
        "ResultDF.loc[len(ResultDF)] = row_result\n",
        "\n",
        "del best_params, best_score\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kzXVqay1N4I",
        "outputId": "ee1be6af-1ae4-4959-d15f-76e78f9a439e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0/3: Best Fitness = 49.429258\n",
            "Iteration 1/3: Best Fitness = 46.6626939041764\n",
            "Iteration 2/3: Best Fitness = 46.52679304763867\n",
            "Best Parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}\n",
            "Best Score (MSE): 46.52679304763867\n",
            "MAE: 4.974294205273293\n",
            "RMSE: 6.8210551271514195\n",
            "MAPE: 0.03553166868148823\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "440"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM"
      ],
      "metadata": {
        "id": "nRbhPLwjL0pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrames to NumPy arrays\n",
        "X_train_np = X_train.to_numpy()\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# Print shapes\n",
        "print(\"Original X_train_np shape:\", X_train_np.shape)\n",
        "print(\"Original X_test_np shape:\", X_test_np.shape)\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Define hyperparameter space for LSTM\n",
        "space_lstm = {\n",
        "    'n_units': [50, 100, 150],  # Number of LSTM units\n",
        "    'learning_rate': [0.001, 0.01, 0.1],  # Learning rates\n",
        "    'batch_size': [16, 32, 64],  # Batch sizes\n",
        "    'epochs': [50, 100]  # Number of epochs\n",
        "}\n",
        "\n",
        "# Map GWO positions to LSTM hyperparameters correctly for LSTM (4 hyperparameters)\n",
        "def map_params(position):\n",
        "    indices = [\n",
        "        min(int(position[0] * len(space_lstm['n_units'])), len(space_lstm['n_units']) - 1),\n",
        "        min(int(position[1] * len(space_lstm['learning_rate'])), len(space_lstm['learning_rate']) - 1),\n",
        "        min(int(position[2] * len(space_lstm['batch_size'])), len(space_lstm['batch_size']) - 1),\n",
        "        min(int(position[3] * len(space_lstm['epochs'])), len(space_lstm['epochs']) - 1)\n",
        "    ]\n",
        "    params = {\n",
        "        'n_units': space_lstm['n_units'][indices[0]],\n",
        "        'learning_rate': space_lstm['learning_rate'][indices[1]],\n",
        "        'batch_size': space_lstm['batch_size'][indices[2]],\n",
        "        'epochs': space_lstm['epochs'][indices[3]]\n",
        "    }\n",
        "    return params\n",
        "\n",
        "def lstm_target_function(position):\n",
        "    params = map_params(position)\n",
        "\n",
        "    # Reshape data for LSTM\n",
        "    timesteps = 1\n",
        "    num_samples, num_features = X_train_np.shape\n",
        "    if num_features % timesteps != 0:\n",
        "        raise ValueError(f\"Number of features ({num_features}) must be divisible by timesteps ({timesteps})\")\n",
        "    n_features = num_features // timesteps\n",
        "\n",
        "    X_train_reshaped = X_train_np.reshape((X_train_np.shape[0], timesteps, n_features))\n",
        "    X_test_reshaped = X_test_np.reshape((X_test_np.shape[0], timesteps, n_features))\n",
        "\n",
        "    # Build LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(timesteps, n_features)))  # Define input shape\n",
        "    model.add(LSTM(params['n_units'], activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=Adam(learning_rate=params['learning_rate']), loss='mse')\n",
        "\n",
        "    # Train LSTM model\n",
        "    history = model.fit(X_train_reshaped, y_train, epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, validation_split=0.1)\n",
        "\n",
        "    # # Inspect training history\n",
        "    # print(\"Training Loss History:\", history.history['loss'])\n",
        "\n",
        "    # Predict on the test set\n",
        "    preds = model.predict(X_test_reshaped).flatten()\n",
        "\n",
        "    # Replace NaNs in predictions if any\n",
        "    preds = np.nan_to_num(preds, nan=0.0)\n",
        "\n",
        "    # Check for NaNs in y_test and preds\n",
        "    if np.any(np.isnan(y_test)):\n",
        "        raise ValueError(\"y_test contains NaN values.\")\n",
        "    if np.any(np.isnan(preds)):\n",
        "        raise ValueError(\"Predictions contain NaN values.\")\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    return mse\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Configuration for the GWO\n",
        "dim = 4  # Number of hyperparameters\n",
        "n_agents = Conf.number_wolves\n",
        "n_iter = Conf.iterator_deeplearning\n",
        "timesteps = (X_train_np.shape[1])\n",
        "min_values = [0] * dim  # Lower bounds for GWO\n",
        "max_values = [1] * dim  # Upper bounds for GWO\n",
        "\n",
        "# Run Grey Wolf Optimizer\n",
        "best_params, best_score = grey_wolf_optimizer(\n",
        "    pack_size=n_agents,\n",
        "    min_values=min_values,\n",
        "    max_values=max_values,\n",
        "    iterations=n_iter,\n",
        "    target_function=lstm_target_function,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score (MSE):\", best_score)\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Use the best parameters found by GWO directly\n",
        "final_params_lstm = best_params\n",
        "timesteps = 1\n",
        "num_samples, n_features = X_train_np.shape\n",
        "\n",
        "# Reshape input data for final training\n",
        "X_train_reshaped = X_train_np.reshape((X_train_np.shape[0], timesteps, n_features))\n",
        "X_test_reshaped = X_test_np.reshape((X_test_np.shape[0], timesteps, n_features))\n",
        "\n",
        "# Define and compile the LSTM model with the best hyperparameters\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(timesteps, n_features)))  # Define input shape\n",
        "model.add(LSTM(final_params_lstm['n_units'], activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer=Adam(learning_rate=final_params_lstm['learning_rate']), loss='mse')\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_reshaped, y_train, epochs=final_params_lstm['epochs'], batch_size=final_params_lstm['batch_size'], verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "preds = model.predict(X_test_reshaped).flatten()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, preds)\n",
        "mape = mean_absolute_percentage_error(y_test, preds)\n",
        "\n",
        "print(\"Final LSTM Model Metrics:\")\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAPE:\", mape)\n",
        "\n",
        "# Append result to DataFrame\n",
        "row_result = [\"LSTM\", Conf.Subjects, Conf.Subjects * Conf.CGM_Inputs, mae, rmse, mape]\n",
        "ResultDF.loc[len(ResultDF)] = row_result\n",
        "\n",
        "del best_params, best_score\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "10pFqFATui4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2c17a1-b58e-4f91-c4ff-494d7ff43423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X_train_np shape: (800, 14)\n",
            "Original X_test_np shape: (200, 14)\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7931ec64af80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7931ebd6f5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Iteration 0/2: Best Fitness = 77.330727918361\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Iteration 1/2: Best Fitness = 42.970649386611186\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 282ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Best Parameters: {'n_units': 150, 'learning_rate': 0.01, 'batch_size': 32, 'epochs': 50}\n",
            "Best Score (MSE): 42.625940559311424\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 6930.1777\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 437.1343\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 299.8144\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 311.1924\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 249.8499\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 245.2534\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 205.7806\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 164.3969\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 118.8217\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 121.6982\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 96.1931\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 68.5361\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 74.1432\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 84.4288\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 88.3448\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 93.5669\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 85.2846\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 79.5172\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 65.5044\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 101.9989\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.9804\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.1676\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 87.2620\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.0545\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.6137\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 78.0976\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 78.3142\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 85.4962\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.7966\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 77.3204\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 83.9340 \n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.6910\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 66.0804\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.2200\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.2020\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123.0286\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 94.3350\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 78.5945\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 71.7677\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 58.6540\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.5023\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.9914\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53.8778\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.0627\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 87.4813\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 80.2831\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.9249\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.4815\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 62.6070\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 71.4041\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Final LSTM Model Metrics:\n",
            "MAE: 4.673711833953857\n",
            "RMSE: 6.44831142965767\n",
            "MAPE: 0.03459045923766743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1043"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GRU"
      ],
      "metadata": {
        "id": "fdlypFsx_NaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrames to NumPy arrays\n",
        "X_train_np = X_train.to_numpy()\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# Print shapes\n",
        "print(\"Original X_train_np shape:\", X_train_np.shape)\n",
        "print(\"Original X_test_np shape:\", X_test_np.shape)\n",
        "\n",
        "# Define hyperparameter space for GRU\n",
        "space_gru = {\n",
        "    'n_units': [50, 100, 150],  # Number of GRU units\n",
        "    'learning_rate': [0.001, 0.01, 0.1],  # Learning rates\n",
        "    'batch_size': [16, 32, 64],  # Batch sizes\n",
        "    'epochs': [50, 100]  # Number of epochs\n",
        "}\n",
        "\n",
        "# Map GWO positions to GRU hyperparameters\n",
        "def map_params(position):\n",
        "    indices = [\n",
        "        min(int(position[0] * len(space_gru['n_units'])), len(space_gru['n_units']) - 1),\n",
        "        min(int(position[1] * len(space_gru['learning_rate'])), len(space_gru['learning_rate']) - 1),\n",
        "        min(int(position[2] * len(space_gru['batch_size'])), len(space_gru['batch_size']) - 1),\n",
        "        min(int(position[3] * len(space_gru['epochs'])), len(space_gru['epochs']) - 1)\n",
        "    ]\n",
        "    params = {\n",
        "        'n_units': space_gru['n_units'][indices[0]],\n",
        "        'learning_rate': space_gru['learning_rate'][indices[1]],\n",
        "        'batch_size': space_gru['batch_size'][indices[2]],\n",
        "        'epochs': space_gru['epochs'][indices[3]]\n",
        "    }\n",
        "    return params\n",
        "\n",
        "# Define the target function for the GRU model\n",
        "def gru_target_function(position):\n",
        "    params = map_params(position)\n",
        "\n",
        "    # Reshape data for GRU\n",
        "    timesteps = 1\n",
        "    num_samples, num_features = X_train_np.shape\n",
        "    if num_features % timesteps != 0:\n",
        "        raise ValueError(f\"Number of features ({num_features}) must be divisible by timesteps ({timesteps})\")\n",
        "    n_features = num_features // timesteps\n",
        "\n",
        "    X_train_reshaped = X_train_np.reshape((X_train_np.shape[0], timesteps, n_features))\n",
        "    X_test_reshaped = X_test_np.reshape((X_test_np.shape[0], timesteps, n_features))\n",
        "\n",
        "    # Build GRU model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(timesteps, n_features)))  # Define input shape\n",
        "    model.add(GRU(params['n_units'], activation='relu'))  # Use GRU instead of LSTM\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=Adam(learning_rate=params['learning_rate']), loss='mse')\n",
        "\n",
        "    # Train GRU model\n",
        "    history = model.fit(X_train_reshaped, y_train, epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, validation_split=0.1)\n",
        "\n",
        "    # Predict on the test set\n",
        "    preds = model.predict(X_test_reshaped).flatten()\n",
        "\n",
        "    # Replace NaNs in predictions if any\n",
        "    preds = np.nan_to_num(preds, nan=0.0)\n",
        "\n",
        "    # Check for NaNs in y_test and preds\n",
        "    if np.any(np.isnan(y_test)):\n",
        "        raise ValueError(\"y_test contains NaN values.\")\n",
        "    if np.any(np.isnan(preds)):\n",
        "        raise ValueError(\"Predictions contain NaN values.\")\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    return mse\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "dim = 4  # Number of hyperparameters\n",
        "n_agents = Conf.number_wolves\n",
        "n_iter = Conf.iterator_deeplearning\n",
        "timesteps = 1\n",
        "min_values = [0] * dim  # Lower bounds for GWO\n",
        "max_values = [1] * dim  # Upper bounds for GWO\n",
        "\n",
        "# Run Grey Wolf Optimizer\n",
        "best_params, best_score = grey_wolf_optimizer(\n",
        "    pack_size=n_agents,\n",
        "    min_values=min_values,\n",
        "    max_values=max_values,\n",
        "    iterations=n_iter,\n",
        "    target_function=gru_target_function,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "# Use the best parameters found by GWO directly\n",
        "final_params_gru = best_params\n",
        "timesteps = 1\n",
        "num_samples, n_features = X_train_np.shape\n",
        "\n",
        "print(\"Best Parameters:\", final_params_gru)\n",
        "print(\"Best Score (MSE):\", best_score)\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Reshape input data for final training\n",
        "X_train_reshaped = X_train_np.reshape((X_train_np.shape[0], timesteps, n_features))\n",
        "X_test_reshaped = X_test_np.reshape((X_test_np.shape[0], timesteps, n_features))\n",
        "\n",
        "# Define and compile the GRU model with the best hyperparameters\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(timesteps, n_features)))  # Define input shape\n",
        "model.add(GRU(final_params_gru['n_units'], activation='relu'))  # Use GRU instead of LSTM\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer=Adam(learning_rate=final_params_gru['learning_rate']), loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_reshaped, y_train, epochs=final_params_gru['epochs'], batch_size=final_params_gru['batch_size'], verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "preds = model.predict(X_test_reshaped).flatten()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, preds)\n",
        "mape = mean_absolute_percentage_error(y_test, preds)\n",
        "\n",
        "print(\"Final GRU Model Metrics:\")\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAPE:\", mape)\n",
        "\n",
        "# Append result to DataFrame\n",
        "row_result = [\"GRU\", Conf.Subjects, Conf.Subjects * Conf.CGM_Inputs, mae, rmse, mape]\n",
        "ResultDF.loc[len(ResultDF)] = row_result\n",
        "\n",
        "del best_params, best_score\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvLi6CqJ8a8h",
        "outputId": "441935f1-b967-46be-99f0-f07f3ffce71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X_train_np shape: (800, 14)\n",
            "Original X_test_np shape: (200, 14)\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "Iteration 0/2: Best Fitness = 72.55569864051678\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Iteration 1/2: Best Fitness = 40.56530877679208\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prophet"
      ],
      "metadata": {
        "id": "BqXI_9APCIUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for Prophet\n",
        "prophet_data = pd.DataFrame({\n",
        "    'ds': pd.to_datetime(final_data['date']),\n",
        "    'y': final_data['mg/dl']\n",
        "})\n",
        "\n",
        "# Define the hyperparameter space for Prophet\n",
        "space_prophet = {\n",
        "    'seasonality_mode': ['additive', 'multiplicative'],\n",
        "    'seasonality_prior_scale': [1, 10, 100],\n",
        "    'holidays_prior_scale': [1, 10, 100],\n",
        "    'changepoint_prior_scale': [0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "# Function to map GWO positions to Prophet parameters\n",
        "def map_params(position):\n",
        "    # Ensure positions are within bounds [0, 1]\n",
        "    position = np.clip(position, 0, 1)\n",
        "\n",
        "    indices = [\n",
        "        min(int(position[0] * len(space_prophet['seasonality_mode'])), len(space_prophet['seasonality_mode']) - 1),\n",
        "        min(int(position[1] * len(space_prophet['seasonality_prior_scale'])), len(space_prophet['seasonality_prior_scale']) - 1),\n",
        "        min(int(position[2] * len(space_prophet['holidays_prior_scale'])), len(space_prophet['holidays_prior_scale']) - 1),\n",
        "        min(int(position[3] * len(space_prophet['changepoint_prior_scale'])), len(space_prophet['changepoint_prior_scale']) - 1)\n",
        "    ]\n",
        "\n",
        "    params = {\n",
        "        'seasonality_mode': space_prophet['seasonality_mode'][indices[0]],\n",
        "        'seasonality_prior_scale': space_prophet['seasonality_prior_scale'][indices[1]],\n",
        "        'holidays_prior_scale': space_prophet['holidays_prior_scale'][indices[2]],\n",
        "        'changepoint_prior_scale': space_prophet['changepoint_prior_scale'][indices[3]]\n",
        "    }\n",
        "    return params\n",
        "\n",
        "# Prophet target function for GWO\n",
        "def prophet_target_function(position):\n",
        "    params = map_params(position)\n",
        "\n",
        "    # Initialize Prophet with mapped parameters\n",
        "    model = Prophet(\n",
        "        seasonality_mode=params['seasonality_mode'],\n",
        "        seasonality_prior_scale=params['seasonality_prior_scale'],\n",
        "        holidays_prior_scale=params['holidays_prior_scale'],\n",
        "        changepoint_prior_scale=params['changepoint_prior_scale']\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Fit the model with the data\n",
        "        model.fit(prophet_data)\n",
        "\n",
        "        # Make predictions\n",
        "        future = model.make_future_dataframe(periods=365)  # Define future periods\n",
        "        forecast = model.predict(future)\n",
        "\n",
        "        # Align predictions with actual values\n",
        "        y_pred = forecast.loc[forecast['ds'].isin(prophet_data['ds']), 'yhat'].values\n",
        "        y_test = prophet_data['y'].values  # Actual target values\n",
        "\n",
        "        # Ensure lengths match for evaluation\n",
        "        if len(y_pred) != len(y_test):\n",
        "            print(\"Length mismatch between y_test and y_pred.\")\n",
        "            return float('inf')  # Return a large error if lengths do not match\n",
        "\n",
        "        # Compute RMSE as the evaluation metric\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        return rmse\n",
        "    except Exception as e:\n",
        "        print(\"Error in Prophet training/prediction:\", e)\n",
        "        return float('inf')  # Return a large error if Prophet fails\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "# GWO Configuration\n",
        "dim = 4  # Dimensions of parameter space\n",
        "n_agents = Conf.number_wolves\n",
        "n_iter = Conf.iterator\n",
        "min_values = [0] * dim  # Lower bounds\n",
        "max_values = [1] * dim  # Upper bounds\n",
        "\n",
        "# Run Grey Wolf Optimizer for Prophet\n",
        "best_position, best_score = grey_wolf_optimizer(\n",
        "    pack_size=n_agents,\n",
        "    min_values=min_values,\n",
        "    max_values=max_values,\n",
        "    iterations=n_iter,\n",
        "    target_function=prophet_target_function,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Convert the best position to hyperparameters\n",
        "final_params_prophet = best_position\n",
        "\n",
        "# Debugging: Print to ensure correct parameters\n",
        "print(\"Best Parameters for Prophet:\", final_params_prophet)\n",
        "print(\"Best Score (RMSE) for Prophet:\", best_score)\n",
        "\n",
        "# Train Prophet with the best hyperparameters\n",
        "best_model = Prophet(\n",
        "    seasonality_mode=final_params_prophet['seasonality_mode'],\n",
        "    seasonality_prior_scale=final_params_prophet['seasonality_prior_scale'],\n",
        "    holidays_prior_scale=final_params_prophet['holidays_prior_scale'],\n",
        "    changepoint_prior_scale=final_params_prophet['changepoint_prior_scale']\n",
        ")\n",
        "\n",
        "# Fit the model with training data\n",
        "best_model.fit(prophet_data)\n",
        "\n",
        "# Make predictions with the best model\n",
        "future = best_model.make_future_dataframe(periods=365)\n",
        "forecast = best_model.predict(future)\n",
        "preds = forecast.loc[forecast['ds'].isin(prophet_data['ds']), 'yhat'].values\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = mean_squared_error(prophet_data['y'], preds)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(prophet_data['y'], preds)\n",
        "mape = mean_absolute_percentage_error(prophet_data['y'], preds)\n",
        "\n",
        "print(\"Final Prophet Model Metrics:\")\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAPE:\", mape)\n",
        "\n",
        "# Append result to DataFrame\n",
        "row_result = [\"Prophet\", Conf.Subjects, Conf.Subjects * Conf.CGM_Inputs, mae, rmse, mape]\n",
        "ResultDF.loc[len(ResultDF)] = row_result"
      ],
      "metadata": {
        "id": "BVFV4vdN8gl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save all the results"
      ],
      "metadata": {
        "id": "PtiWN5odHsOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResultDF"
      ],
      "metadata": {
        "id": "K7teRIbw8gci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResultDF.to_csv('GWO_Model_Training.csv', index=False)"
      ],
      "metadata": {
        "id": "sfOTR1iK8gZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bSIaPRkuGSJX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}